{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e1654b6-c51f-428f-82b5-d187f7bcc884",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from uvicorn import run\n",
    "# import agenta\n",
    "# import _app  # This will register the routes with the FastAPI application\n",
    "# import os\n",
    "\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     run(\"agenta:app\", host=\"0.0.0.0\", port=80)\n",
    "# root@473612b48a22:/app# cat _\n",
    "# __pycache__/ _app.py      \n",
    "# root@473612b48a22:/app# cat _app.py \n",
    "import agenta as ag\n",
    "import litellm\n",
    "\n",
    "ag.init()\n",
    "\n",
    "prompts = {\n",
    "    \"system_prompt\": \"You are an expert in geography.\",\n",
    "    \"user_prompt\": \"\"\"What is the capital of {country}?\"\"\",\n",
    "\n",
    "}\n",
    "\n",
    "# ChatGPT 3.5 models\n",
    "CHAT_LLM_GPT = [\n",
    "    \"gpt-3.5-turbo-16k-0613\",\n",
    "    \"gpt-3.5-turbo-16k\",\n",
    "    \"gpt-3.5-turbo-1106\",\n",
    "    \"gpt-3.5-turbo-0613\",\n",
    "    \"gpt-3.5-turbo-0301\",\n",
    "    \"gpt-3.5-turbo\",\n",
    "    \"gpt-4\",\n",
    "    \"gpt-4-1106-preview\",\n",
    "]\n",
    "GPT_FORMAT_RESPONSE = [\"gpt-3.5-turbo-1106\", \"gpt-4-1106-preview\"]\n",
    "ag.config.default(\n",
    "    temperature=ag.FloatParam(default=1, minval=0.0, maxval=2.0),\n",
    "    model=ag.MultipleChoiceParam(\n",
    "        \"gpt-3.5-turbo\", CHAT_LLM_GPT\n",
    "    ),\n",
    "    max_tokens=ag.IntParam(-1, -1, 4000),\n",
    "    prompt_system=ag.TextParam(prompts[\"system_prompt\"]),\n",
    "    prompt_user=ag.TextParam(prompts[\"user_prompt\"]),\n",
    "    top_p=ag.FloatParam(1),\n",
    "    frequence_penalty=ag.FloatParam(default=0.0, minval=-2.0, maxval=2.0),\n",
    "    presence_penalty=ag.FloatParam(default=0.0, minval=-2.0, maxval=2.0),\n",
    "    force_json=ag.BinaryParam(False)\n",
    ")\n",
    "\n",
    "\n",
    "@ag.entrypoint\n",
    "async def generate(\n",
    "    inputs: ag.DictInput = ag.DictInput(default_keys=[\"country\"]),\n",
    "):\n",
    "    try:\n",
    "        prompt_user = ag.config.prompt_user.format(**inputs)\n",
    "    except Exception as e:\n",
    "        prompt_user = ag.config.prompt_user\n",
    "    try:\n",
    "        prompt_system = ag.config.prompt_system.format(**inputs)\n",
    "    except Exception as e:\n",
    "        prompt_system = ag.config.prompt_system\n",
    "\n",
    "    max_tokens = ag.config.max_tokens if ag.config.max_tokens != -1 else None\n",
    "    # SET MAX TOKENS - via completion()\n",
    "    if ag.config.force_json and ag.config.model not in GPT_FORMAT_RESPONSE:\n",
    "        raise ValueError(\n",
    "            \"Model {} does not support JSON response format\".format(ag.config.model))\n",
    "    response_format = (\n",
    "        {\"type\": \"json_object\"}\n",
    "        if ag.config.force_json and ag.config.model in GPT_FORMAT_RESPONSE\n",
    "        else {\"type\": \"text\"}\n",
    "    )\n",
    "\n",
    "    response = await litellm.acompletion(\n",
    "        model=ag.config.model,\n",
    "        messages=[{\"content\": prompt_system, \"role\": \"system\"},\n",
    "                  {\"content\": prompt_user, \"role\": \"user\"}],\n",
    "        temperature=ag.config.temperature,\n",
    "        max_tokens=max_tokens,\n",
    "        top_p=ag.config.top_p,\n",
    "        frequency_penalty=ag.config.frequence_penalty,\n",
    "        presence_penalty=ag.config.presence_penalty,\n",
    "        response_format=response_format,\n",
    "    )\n",
    "\n",
    "    token_usage = response.usage.dict()\n",
    "    return {\n",
    "        \"message\": response.choices[0].message.content,\n",
    "        **{\"usage\": token_usage},\n",
    "        \"cost\": ag.calculate_token_usage(ag.config.model, token_usage),\n",
    "    }"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
